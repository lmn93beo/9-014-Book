{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bayesian Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes' Rule / Law / Theorem\n",
    "\n",
    "The joint probability $P(X,Y)$ is the probability that two events, $X$ and $Y$, both occur and can be written as:\n",
    "\n",
    "$$ P(X, Y) = P(X | Y) \\times P(Y) $$\n",
    "\n",
    "where $P(Y)$ is the probability that $Y$ occurs and $P(X|Y)$ is the probability that $X$ occurs conditioned on $Y$ occuring.\n",
    "\n",
    "\n",
    "We can easily derive Bayes' Rule from the fact that $P(X,Y) = P(Y,X)$:\n",
    "\n",
    "$$P(X,Y) = P(Y,X)$$\n",
    "\n",
    "$$ P(X | Y) \\times P(Y) = P(Y | X) \\times P(X) $$\n",
    "\n",
    "$$ P(X | Y) = \\frac{P(Y | X) \\times P(X)}{P(Y)} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior, Likelihood, and Posterior\n",
    "\n",
    "$$ \\text{Bayes' Rule:} \\quad P(X | Y) = \\frac{P(Y | X) \\times P(X)}{P(Y)} $$\n",
    "\n",
    "$$ \\text{Posterior} \\propto  \\text{Likelihood} \\times \\text{Prior}$$\n",
    "\n",
    "$P(Y | X)$ : Likelihood function\n",
    "\n",
    "$P(X)$ : Prior probability\n",
    "\n",
    "$P(Y)$ : Marginal probability of $Y$ (normalizing factor)\n",
    "\n",
    "$P(X | Y)$ : Posterior probability\n",
    "\n",
    "The variance of the posterior is always less than or equal to the variance of the prior (the likelihood function of your observation further constrains the posterior).\n",
    "\n",
    "#### Perception example: noisy measurement with prior belief\n",
    "\n",
    "Imagnie trying to estimate the speed of a passing car. Let $S$ represent the stimulus: the passing car. The sensory systems measure various properties about this stimulus (the moving pattern of light striking the retina, the frequency and intensity of the engine noise, etc.). Let $m$ represent the measurement made by the sensory systems. The noisy measurement process can be modeled with the likelihood function $P(m | S)$, which reflects the probability of making the measurement $m$ given a stimulus $S$. In order to best infer the speed of the passing car from the noisy measurements, we want to incorporate both the likelihood function and out prior beliefs.\n",
    "\n",
    "The person is tasked with inferring the speed of the stimulus from this noisy measurement.\n",
    "\n",
    "\n",
    "$S_{\\text{stimulus}}$ ------> $m^*_{\\text{noisy measurement}}$ ------> $S^*_{\\text{estimate of stimulus}}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: false positives of a rare disease\n",
    "\n",
    "The diagnosis of rare diseases is a classic example of how priors influence posterior probabilities. Suppose a rare disease infects 1 in 10,000 people and a test for this disease exists that is 99.9% reliable. We will take 99.9% reliable to mean that the probability of testing positive is 0.999 for infected individuals and 0.001 for healthy individuals. What then is the probability that an individual who tests positive is infected?\n",
    "\n",
    "This probability can be easily calculated using Bayes' Rule. We have two binary random variables:\n",
    "\n",
    "(1) The individual can either have the disease $(D^+)$ or not have the disease $(D^-)$\n",
    "\n",
    "(2) The individual can either test positive $(T^+)$ or test negative $(T^-)$\n",
    "\n",
    "We are interested in the probability $P(D^+ | T^+)$, the probability that a person is infected given a positive test result.\n",
    "\n",
    "According to Bayes' Rule:\n",
    "$$ P(D^+ | T^+) = \\frac{P(T^+ | D^+) \\times P(D^+)}{P(T^+)} $$\n",
    "\n",
    "From the question, we know:\n",
    "\n",
    "$P(D^+) = 0.0001 \\quad$ since the disease infects 1 in 10,000 people\n",
    "\n",
    "$P(T^+ | D^+) = 0.999 \\quad$ since the test is 99.9% reliable\n",
    "\n",
    "$P(T^- | D^-) = 0.999 \\quad$ since the test is 99.9% reliable\n",
    "\n",
    "Thus we also know that $P(D^-) = 1 - P(D^+) = 0.9999$ and $P(T^+ | D^-) = 1 - P(T^- | D^-) = 0.001$. We will use these facts to calculate $P(T^+)$ by marginalizing over the possible values of $D$:\n",
    "\n",
    "$$ P(T^+) = P(T^+, D^-) + P(T^+, D^+) $$\n",
    "\n",
    "$$ P(T^+, D^-) = P(T^+ | D^-) \\times P(D^-) = 0.001 \\times 0.9999 = 0.0009999 $$\n",
    "\n",
    "$$ P(T^+, D^+) = P(T^+ | D^+) \\times P(D^+) = 0.999 \\times 0.0001 = 0.0000999 $$\n",
    "\n",
    "$$ P(T^+) = 0.0009999 + 0.0000999 = 0.0010998$$\n",
    "\n",
    "Using Bayes' Rule we can solve for the probability of being infected with the rare disease given a positive test result:\n",
    "\n",
    "$$ P(D^+ | T^+) = \\frac{P(T^+ | D^+) \\times P(D^+)}{P(T^+)} = \\frac{0.999 \\times 0.0001}{0.0010998} \\approx 0.0908$$\n",
    "\n",
    "A person who tests positively has less than a 10% chance of actually being infected by the rare disease! How is this possible?\n",
    "\n",
    "The answer lies in the prior. The disease is very rare so the prior probability of a person being infected is very low. Even though the **likelihood** of being infected seems high given a positive test result (99.9%), there is such a strong **prior** that the person does not have the disease (0.001%), the resulting **posterior** probability of being infected is still very low.\n",
    "\n",
    "Clearly a test with 99.9% reliability is not good enough for such a rare disease. Imagine we instead wanted a test that had a false positive rate of less than 20%. How reliable must the test be in order to have $P(D^+ | T^+) = 0.80$? To answer this question, we would solve Bayes' Rule for $P(T^+ | D^+)$:\n",
    "\n",
    "$$ P(D^+ | T^+) = \\frac{P(T^+ | D^+) \\times P(D^+)}{P(T^+)} $$\n",
    "\n",
    "To make the notation easier, we will use $r = P(T^+ | D^+)$ to represent the reliability of the test.\n",
    "\n",
    "$$ P(D^+ | T^+) = \\frac{r \\times P(D^+)}{P(T^+, D^-) + P(T^+, D^+)} $$\n",
    "\n",
    "$$ P(D^+ | T^+) = \\frac{r \\times P(D^+)}{\\big(P(T^+ | D^-) \\times P(D^-)\\big) + \\big(P(T^+ | D^+) \\times P(D^+)\\big)} $$\n",
    "\n",
    "Since we defined reliability as $P(D^+ | D^+) = P(T^- | D^-)$, we can replace $P(T^+ | D^-)$ with $1-r$, which leaves us with:\n",
    "\n",
    "$$ P(D^+ | T^+) = \\frac{r \\times P(D^+)}{(1-r) \\times P(D^-) + r \\times P(D^+)} $$\n",
    "\n",
    "To make the notation easier again, we will let $d = P(D^+)$ and use the fact that $P(D^-) = 1-d$:\n",
    "\n",
    "$$ P(D^+ | T^+) = \\frac{r \\times d}{(1-r) \\times (1-d) + r \\times d} $$\n",
    "\n",
    "Since we know the disease prevalence $d = P(D^+)$ and the desired $P(D^+ | T^+)$ it is simply a matter of algebra to solve for $r$:\n",
    "\n",
    "$$ r =  \\frac{P(D^+ | T^+) - d \\times P(D^+ | T^+)}{\\big(-2 \\times d \\times P(D^+ | T^+)\\big) + d + P(D^+ | T^+)}$$\n",
    "\n",
    "Substituting in the desired $P(D^+ | T^+) = 0.80$ and $d = P(D^+) = 0.0001$ gives $r =  0.999975$. The test needs to be 99.9975% reliable just to achieve a false positive rate of 20%!\n",
    "\n",
    "\n",
    "PLOT?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bayesian Integration in Ready-Set-Go Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian inference in interval timing experiments (Based on Jazayeri and Shadlen, 2010 and 9.014 PSET 5, 2017)\n",
    "\n",
    "In a set of experiments on interval timing, subjects were asked to measure a sample interval and reproduce it afterwards. The sample interval was presented as the time between two flashes of lights, which we will refer to as \"Ready\" and \"Set\". Subjects had to measure the time between Ready and Set and then press and hold a button for the same duration as the sample interval. We will use $t_s$ to indicate the sample intervals and $t_e$ to represent a subject's response (their estimated interval). We are interested in building a simple model to predict the mean and variance of subjects' responses for given sample intervals.\n",
    "\n",
    "\n",
    "In the experiment, sample intervals were drawn from a **discrete uniform distribution**. Subject responses ($t_e$) are plotted as a function of sample interval ($t_s$) below. Near the mean of the distribution over $t_s$, the relationship between $t_e$ and $t_s$ is linear and close to identity. Towards both ends of the distribution, subjects systematically deviate from the identity line: they overestimate shorter sample intervals and underestimate longer sample intervals.\n",
    "\n",
    "\n",
    "--> PLOT HERE <-- (te as a function of ts with mean Â± sem and identity lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This behavior suggests that the subject's estimated intervals are biased by knowledge of the underlying distribution from which sample intervals are drawn. We can model this behavior using a Bayesian inference framework. We will assume that the subject makes a noisy measurement (denoted $t_m$) of the sample interval ($t_s$) and then uses this measurement to produce a Bayesian estimate ($t_e$). We can use Bayes' Rule to model the noisy measurement. Given a sample interval $t_s$, there is some probability distribution over the possible measurements: $P(t_m | t_s)$. For simplicity we will model $P(t_m | t_s)$ as a Gaussian distribution centered at $t_s$ with mean $t_s$ and standard deviation $\\sigma_m$. Intuitively, if $\\sigma_m$ is very small, then the measurements are narrowly distributed around the true interval. If $\\sigma_m$ is large, then the measurements are more broadly distributed around the true interval (measurement process is more noisy).\n",
    "\n",
    "$$ \\text{Likelihood Function:} \\quad P(t_m | t_s) = Gaussian(t_s, \\sigma_m) $$\n",
    "$$ P(t_s | t_m) \\propto P(t_m | t_s) P(t_s)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jazayeri, M. and Shadlen, M.N. (2010). Temporal context calibrates interval timing. Nature Neuroscience. 13 (8):1020-6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
