{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Matrices and Orthonormal Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.1. Notation\n",
    "\n",
    "If a vector is a column of numbers, a matrix can be thought of as a rectangular array of numbers. If it helps, you can think of each matrix as a table where each column is a vector and represents an object. For instance, we can collect Alice and Bob's measurements into a matrix like so\n",
    "\n",
    "$$\n",
    "M = \\begin{bmatrix}\n",
    "\t23 & 31  \\\\\n",
    "\t70       & 80 \\\\\n",
    "\t180       & 185 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where, as we recall, Alice is represented by $\\textbf{a} = (23, 70, 180)$, and Bob by  $\\textbf{b} = (31, 80, 185)$.\n",
    "\n",
    "We say $M$ is a $3\\times 2$ matrix because it has 3 rows and 2 columns. Another way of saying this is that $M$ has *dimension* $3\\times 2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Matrix addition and scalar multiplication\n",
    "\n",
    "Matrix addition and scalar multiplication works the same way as they are defined for vectors. For addition of two matrices, we do add the matrices element-wise and for scalar multiplication, we multiply each entry by that scalar. Note that we can only add two matrices with the same dimension.\n",
    "\n",
    "*Example:* Given $M = \\begin{bmatrix}\n",
    "23 & 31  \\\\\n",
    "70       & 80 \\\\\n",
    "180       & 185 \n",
    "\\end{bmatrix}$ and $ N = \\begin{bmatrix}\n",
    "46 & 18  \\\\\n",
    "60       & 50 \\\\\n",
    "170       & 185 \n",
    "\\end{bmatrix}$, we have\n",
    "\n",
    "\\begin{align*}\n",
    "M + N &= \\begin{bmatrix}\n",
    "69 & 49  \\\\\n",
    "130       & 130 \\\\\n",
    "350       & 370 \n",
    "\\end{bmatrix}\\\\\n",
    "2N &= \\begin{bmatrix}\n",
    "92 & 36  \\\\\n",
    "120       & 100 \\\\\n",
    "340       & 370 \n",
    "\\end{bmatrix}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication\n",
    "\n",
    "Matrix multiplication can be tricky to get used to at first. We will introduce this operation slowly, starting from multiplying a matrix by a vector and then go on to multiplying two matrices.\n",
    "\n",
    "Example: given $\\textbf{W} = \\begin{bmatrix}\n",
    "3 & 4 & 5\\\\\n",
    "1 & 0 & 1\n",
    "\\end{bmatrix}$ and $\\textbf{v} = \\begin{bmatrix}\n",
    "1\\\\0\\\\2\n",
    "\\end{bmatrix}$, we want to find the product $\\textbf{Wv}$.\n",
    "\n",
    "Now the first thing that we should check is the dimensions of the things we're multiplying. $\\textbf{W}$ has dimension $2\\times 3$ and $\\textbf{v}$ has dimension $3\\times 1$. Since the number of columns of $\\textbf{W}$ = the number of rows of $\\textbf{v}$, we say these two matrices are *compatible*, and we know that the product $\\textbf{Wv}$ has dimension $2\\times 1$. In general, mutliplying an $m\\times p$ matrix with a $p\\times n$ matrix gives an $m\\times n$ matrix.\n",
    "\n",
    "Now on to the mechanics of the multiplication. There are two different ways of doing this, both will give you the same result. You will see that it is useful to be able to interpret the multiplication in these two different ways.\n",
    "\n",
    "** Method 1 **\n",
    "\n",
    "We find the dot product between *the rows of $\\textbf{M}$* and $\\textbf{w}$.\n",
    "\n",
    "In the end, we get the following result\n",
    "\n",
    "$$\\textbf{Wv} = \\begin{bmatrix}\n",
    "3 & 4 & 5\\\\\n",
    "1 & 0 & 1\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "1\\\\0\\\\2\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "3 . 1 + 4 . 0 + 5 . 2\\\\1.1 + 0.0 + 1.2\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "13\\\\3\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "** Method 2 **\n",
    "\n",
    "Another way of viewing this multiplication is to think of the product as a linear combination of the *columns* of $W$, weighted by the coefficients of the vector $v$. So,\n",
    "\n",
    "$$\n",
    "\\textbf{Wv} = \\begin{bmatrix}\n",
    "3 & 4 & 5\\\\\n",
    "1 & 0 & 1\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "1\\\\0\\\\2\n",
    "\\end{bmatrix} = 1 . \\begin{bmatrix}\n",
    "3 \\\\ 1\n",
    "\\end{bmatrix} +  0 . \\begin{bmatrix}\n",
    "4 \\\\ 0\n",
    "\\end{bmatrix} +  2 . \\begin{bmatrix}\n",
    "5 \\\\ 1\n",
    "\\end{bmatrix} =  \\begin{bmatrix}\n",
    "13 \\\\ 3\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Hopefully that wasn't too confusing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Linear transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Orthonormal matrices (rotation matrices)\n",
    "\n",
    "Remember what an orthonormal basis is? It is a collection of vectors that satisfy the following two properties:\n",
    "\n",
    "(1) All these vectors must be *perpendicular* to each other.\n",
    "\n",
    "(2) Each of these vectors must have a length of 1.\n",
    "\n",
    "For instance, $(1,0)$ and $(0,1)$ form an orthonormal basis. So do $\\left(\\frac{1}{\\sqrt{2}}, \\frac{1}{\\sqrt{2}}\\right)$ and $\\left(\\frac{1}{\\sqrt{2}}, \\frac{-1}{\\sqrt{2}}\\right)$.\n",
    "\n",
    "What about the following three vectors: $\\left(\\frac{1}{3}, \\frac{2}{3}, \\frac{2}{3}\\right)$, $\\left(\\frac{2}{3}, \\frac{1}{3}, \\frac{-2}{3}\\right)$, and $\\left(\\frac{2}{3}, \\frac{-2}{3}, \\frac{1}{3}\\right)$. Do they form an orthonormal basis?\n",
    "\n",
    "We need to check the two conditions.\n",
    "\n",
    "(1) Are they perpendicular to each other? Yes! Let's take one pair as an example. \n",
    "\n",
    "$$\\left(\\frac{1}{3}, \\frac{2}{3}, \\frac{2}{3}\\right). \\left(\\frac{2}{3}, \\frac{1}{3}, \\frac{-2}{3}\\right) = \\frac{1}{3} . \\frac{2}{3} + \\frac{2}{3} . \\frac{1}{3} + \\frac{2}{3} . \\frac{-2}{3} = 0$$.\n",
    "\n",
    "You can verify that the other two pairs also work similarly.\n",
    "\n",
    "(2) Does each of them have length 1? Yes! Let's find the length of the first vector, $\\left(\\frac{1}{3}, \\frac{2}{3}, \\frac{2}{3}\\right)$.\n",
    "\n",
    "$$\\sqrt{\\left(\\frac{1}{3}\\right)^2 + \\left(\\frac{2}{3}\\right)^2 + \\left(\\frac{2}{3}\\right)^2} = 1$$.\n",
    "\n",
    "Similarly, the lengths of the other two vectors are also 1. So these three vectors form an orthonormal basis.\n",
    "\n",
    "Now what is an **orthonormal matrix** and why is it important?\n",
    "\n",
    "An orthonormal matrix (also known as a **rotation matrix** for reasons that will become obvious later) is a matrix whose columns form an orthonormal basis. For example, $\n",
    "\\begin{bmatrix}\n",
    "\t1 & 0  \\\\\n",
    "\t0       & 1 \n",
    "\\end{bmatrix}\n",
    "$\n",
    "is an orthonormal matrix because its two columns, $(1,0)$ and $(0,1)$ form an orthonormal matrix as we have discussed. In the same way, these two matrices are orthonormal [Why?]\n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "\t\\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}}  \\\\\n",
    "\t\\frac{1}{\\sqrt{2}} & \\frac{-1}{\\sqrt{2}} \n",
    "\\end{bmatrix}\n",
    "$\n",
    "and \n",
    "$\n",
    "\\begin{bmatrix}\n",
    "\t\\frac{2}{3} & \\frac{1}{3} & \\frac{2}{3}  \\\\\n",
    "\t\\frac{-2}{3} & \\frac{2}{3} & \\frac{1}{3} \\\\\n",
    "    \\frac{1}{3} & \\frac{2}{3} & \\frac{-2}{3}\n",
    "\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.3. Some cool properties of orthonormal matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know what orthonormal matrices are, let's look at some nice properties of these matrices.\n",
    "\n",
    "(a) Rows of orthonormal matrices\n",
    "\n",
    "The first property is pretty cool. Recall that the columns of orthonormal matrices form an orthonormal basis? It turns out that the *columns of orthonormal matrices also form an orthonormal basis*.\n",
    "\n",
    "Let's look at our previous examples. Let's look at $\n",
    "\\begin{bmatrix}\n",
    "\t1 & 0  \\\\\n",
    "\t0       & 1 \n",
    "\\end{bmatrix}\n",
    "$. We know the columns of this matrix are $(1,0)$ and $(0,1)$ which is an orthonormal basis. Let's see what the rows are. $(1,0)$ and $(0,1)$ - also an orthonormal basis!\n",
    "\n",
    "In the same way, the rows of $\n",
    "\\begin{bmatrix}\n",
    "\t\\frac{2}{3} & \\frac{1}{3} & \\frac{2}{3}  \\\\\n",
    "\t\\frac{-2}{3} & \\frac{2}{3} & \\frac{1}{3} \\\\\n",
    "    \\frac{1}{3} & \\frac{2}{3} & \\frac{-2}{3}\n",
    "\\end{bmatrix}\n",
    "$\n",
    "are $\\left(\\frac{2}{3}, \\frac{1}{3}, \\frac{2}{3}\\right)$, $\\left(\\frac{-2}{3}, \\frac{2}{3}, \\frac{1}{3}\\right)$, and $\\left(\\frac{1}{3}, \\frac{2}{3}, \\frac{-2}{3}\\right)$. You can verify that this is an orthonormal basis. [Remember how?]\n",
    "\n",
    "(b) Properties of the transpose\n",
    "\n",
    "The *transpose* of a matrix $M$ is a matrix $M^T$ where all the columns of $M$ become the rows of $M^T$ and vice versa. \n",
    "\n",
    "For an orthonormal matrix, the transpose is its inverse. In other words, if $M$ is an orthonormal matrix, then\n",
    "\n",
    "$$MM^T = M^TM = I$$\n",
    "\n",
    "where $I$ is the identity matrix.\n",
    "\n",
    "(c) Length preserving transformation\n",
    "\n",
    "This property is also pretty cool. If you multiply an orthonormal matrix by *any* vector $\\textbf{v}$, you get another vector with *the same length as **v** *. Effectively, this matrix only has a rotational effect on the vector $v$ and no scaling (it preserves the length of $v$).\n",
    "\n",
    "Let's do an example. First, let's start with the matrix we all know and love, $I = \\begin{bmatrix}\n",
    "\t1 & 0  \\\\\n",
    "\t0       & 1 \n",
    "\\end{bmatrix}$. This is an identity matrix, so multiplying $I$ with any vector $v$ just gives you the same vector back.\n",
    "\n",
    "$$Iv = v$$.\n",
    "\n",
    "The result is a \"rotated\" version of $v$ (rotated by 0 degrees), with the same length as before.\n",
    "\n",
    "Let's \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
